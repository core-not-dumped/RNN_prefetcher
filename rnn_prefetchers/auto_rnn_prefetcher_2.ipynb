{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_rnn_prefetcher_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxtS4fwmP8bP",
        "outputId": "ccf47345-31d4-4dcf-8f7c-22aaf96987d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJv3whtPnEf"
      },
      "source": [
        "##auto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOsLwMAoP8dv"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Input, Dense, Embedding, LSTM\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmwEMAH2QBWm"
      },
      "source": [
        "seq_length = 5 # length of sequence for a training example\n",
        "epoch = 30\n",
        "MAXLEN = 43\n",
        "DENSE_HIDDEN_SIZE = 20\n",
        "train_model_percentage = 90\n",
        "\n",
        "ADDRESS_PREDICT_SIZE = 1001\n",
        "EMBEDDING_DIM = 64\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0nOueN-QJ3m"
      },
      "source": [
        "#f = open(\"473.astar-s0.txt\", 'r')\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/dataset/473.astar-s0.txt', 'r')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB8HZNvrQKad",
        "outputId": "2703dc38-03aa-41c9-e1e3-8273f6bd0f95"
      },
      "source": [
        "load_address = list()\n",
        "\n",
        "f.seek(0, 0)\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  if not line: break\n",
        "  split_line = line.split(', ')\n",
        "  load_address.append(split_line[2])\n",
        "\n",
        "for i in range(len(load_address)):\n",
        "  load_address[i] = int(load_address[i], 16)//64\n",
        "\n",
        "print(\"\\nload_address example: \")\n",
        "print(load_address[:100])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "load_address example: \n",
            "[702778646977, 702778647164, 702778646976, 702778646921, 702778647176, 702778647287, 702778647353, 702778647368, 702778647452, 702778647286, 702778647484, 702778647560, 702778647644, 702778647688, 702778647352, 702778647755, 702778647819, 702778647901, 702778647933, 4363500793931, 702778647351, 702778647820, 702778647756, 4363500793932, 4363500794023, 4363500794087, 174026416743, 702778647350, 174026416807, 174026416838, 2627809326406, 2627809326492, 2627809326524, 2627809326534, 2627809326620, 702778647349, 2627809326662, 2627809326780, 2627809326844, 2627809326857, 2627809326889, 2627809326972, 2627809326988, 2627809327052, 2627809327116, 2627809327180, 2627809327277, 2627809327309, 2627809327341, 702778647348, 2627809327115, 2627809327366, 2627809327430, 2627809327532, 2627809327564, 2627809327596, 2627809327622, 2627809327686, 2627809327749, 702778647347, 2627809327813, 2627809327877, 2627809327979, 2627809328011, 2627809328043, 2627809327947, 2627809328069, 2627809328133, 702778647346, 2627809328204, 2627809328268, 2627809328365, 2627809328396, 2627809328333, 2627809328203, 2627809328471, 2627809328535, 2627809328624, 2627809328656, 2627809328727, 2627809328688, 2627809328791, 2627809328592, 2627809328855, 2627809328944, 702778647345, 2627809328983, 702778647344, 2627809327191, 2627809329047, 2627809327248, 2627809327280, 2627809327127, 2627809327312, 2627809329111, 2627809327063, 2627809327344, 702778647343, 2627809329165, 2627809329228]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR25Noa9QMcn",
        "outputId": "6e40004a-4c61-431c-9c65-3676211f6288"
      },
      "source": [
        "delta = list()\n",
        "for i in range(len(load_address)-1):\n",
        "  delta.append(load_address[i+1] - load_address[i])\n",
        "\n",
        "for i in range(len(delta)):\n",
        "  if delta[i] > 500:\n",
        "    delta[i] = 1000\n",
        "    continue\n",
        "  if delta[i] < -500:\n",
        "    delta[i] = 0\n",
        "    continue\n",
        "  delta[i] += 500\n",
        "\n",
        "print(\"\\ndelta example, final delta:\")\n",
        "print(delta[0:100])\n",
        "print(delta[-1])\n",
        "\n",
        "delta_bundle = list()\n",
        "for i in range(len(delta) - seq_length):\n",
        "  delta_bundle.append(delta[i:i+seq_length+1])\n",
        "delta_bundle = np.array(delta_bundle)\n",
        "\n",
        "print(\"\\ndelta_bundle example:\")\n",
        "print(delta_bundle)\n",
        "\n",
        "rnn_data = delta_bundle[:,:-1]\n",
        "rnn_data = np.array(rnn_data)\n",
        "print(\"\\nfirst input example(rnn_data): \")\n",
        "print(rnn_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "delta example, final delta:\n",
            "[687, 312, 445, 755, 611, 566, 515, 584, 334, 698, 576, 584, 544, 164, 903, 564, 582, 532, 1000, 0, 969, 436, 1000, 591, 564, 0, 1000, 0, 531, 1000, 586, 532, 510, 586, 0, 1000, 618, 564, 513, 532, 583, 516, 564, 564, 564, 597, 532, 532, 0, 1000, 751, 564, 602, 532, 532, 526, 564, 563, 0, 1000, 564, 602, 532, 532, 404, 622, 564, 0, 1000, 564, 597, 531, 437, 370, 768, 564, 589, 532, 571, 461, 603, 301, 763, 589, 0, 1000, 0, 1000, 1000, 0, 532, 347, 685, 1000, 0, 781, 0, 1000, 563, 501]\n",
            "585\n",
            "\n",
            "delta_bundle example:\n",
            "[[ 687  312  445  755  611  566]\n",
            " [ 312  445  755  611  566  515]\n",
            " [ 445  755  611  566  515  584]\n",
            " ...\n",
            " [ 499    0  554  501 1000  499]\n",
            " [   0  554  501 1000  499    0]\n",
            " [ 554  501 1000  499    0  585]]\n",
            "\n",
            "first input example(rnn_data): \n",
            "[[ 687  312  445  755  611]\n",
            " [ 312  445  755  611  566]\n",
            " [ 445  755  611  566  515]\n",
            " ...\n",
            " [ 499    0  554  501 1000]\n",
            " [   0  554  501 1000  499]\n",
            " [ 554  501 1000  499    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRduU2eEQTte",
        "outputId": "275c9fcb-a8e9-4d0c-b4d6-d4cc010181d0"
      },
      "source": [
        "# 8 -> [0,0,0,1] change int to categorical value\n",
        "def address_to_binary(a):\n",
        "  binary_int = list()\n",
        "  for i in range(MAXLEN):\n",
        "    # /1000 -> scaling\n",
        "    binary_int.append(a%2)\n",
        "    a = a//2\n",
        "  return binary_int\n",
        "\n",
        "address_binary_input = list()\n",
        "for i in range(seq_length, len(load_address)-1):\n",
        "  address_binary_input.append(address_to_binary(load_address[i]))\n",
        "\n",
        "print(\"\\naddress binary input example\")\n",
        "print(address_binary_input[0])\n",
        "address_binary_input = np.array(address_binary_input)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "address binary input example\n",
            "[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBpdA-7uQWBu",
        "outputId": "c4457efb-de56-4bf5-8833-d188873c1c64"
      },
      "source": [
        "delta_output = delta_bundle[:,-1:]\n",
        "delta_output = delta_output.flatten()\n",
        "print(\"\\noutput example:\")\n",
        "print(delta_output)\n",
        "\n",
        "print('output shape')\n",
        "print(rnn_data.shape)\n",
        "print(address_binary_input.shape)\n",
        "print(delta_output.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "output example:\n",
            "[566 515 584 ... 499   0 585]\n",
            "output shape\n",
            "(721566, 5)\n",
            "(721566, 43)\n",
            "(721566,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6vxMgoTQXWf",
        "outputId": "16b1545a-daf9-4774-bafa-9ef0f429e1b4"
      },
      "source": [
        "delete_list = list()\n",
        "for i in range(len(delta_output)):\n",
        "  if delta_output[i] == 0 or delta_output[i] == 1000:\n",
        "    delete_list.append(i)\n",
        "\n",
        "delta_output = np.delete(delta_output, delete_list)\n",
        "rnn_data = np.delete(rnn_data, delete_list, 0)\n",
        "address_binary_input = np.delete(address_binary_input, delete_list, 0)\n",
        "\n",
        "print(\"\\n0 and 1000 removed delta output example:\")\n",
        "print(delta_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0 and 1000 removed delta output example:\n",
            "[566 515 584 ... 501 499 585]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWo5AyEKQYz_"
      },
      "source": [
        "idx = np.arange(rnn_data.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "rnn_data = rnn_data[idx]\n",
        "address_binary_input = address_binary_input[idx]\n",
        "delta_output = delta_output[idx]\n",
        "\n",
        "cut_index = len(rnn_data) * train_model_percentage // 100\n",
        "\n",
        "train_rnn_data = rnn_data[:cut_index,:]\n",
        "test_rnn_data = rnn_data[cut_index:]\n",
        "\n",
        "train_address_binary_input = address_binary_input[:cut_index,:]\n",
        "test_address_binary_input = address_binary_input[cut_index:,:]\n",
        "\n",
        "train_delta_output = delta_output[:cut_index]\n",
        "test_delta_output = delta_output[cut_index:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA7ww8QFQZzW"
      },
      "source": [
        "idx = np.arange(train_rnn_data.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "train_rnn_data = train_rnn_data[idx]\n",
        "train_address_binary_input = train_address_binary_input[idx]\n",
        "train_delta_output = train_delta_output[idx]\n",
        "\n",
        "idx = np.arange(test_rnn_data.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "test_rnn_data = test_rnn_data[idx]\n",
        "test_address_binary_input = test_address_binary_input[idx]\n",
        "test_delta_output = test_delta_output[idx]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LzpRpdMPgQW"
      },
      "source": [
        "def build_model(address_predict_size, first_output_size, second_output_size, final_hidden_size, embedding_dim, rnn_units):\n",
        "  \n",
        "  input_x = Input(shape=(seq_length,))\n",
        "  x = Embedding(address_predict_size, embedding_dim)(input_x)\n",
        "  x = LSTM(rnn_units, recurrent_initializer='glorot_uniform') (x)\n",
        "  x = Dense(first_output_size, activation=\"sigmoid\") (x)\n",
        "  x = Model(inputs=input_x, outputs=x)\n",
        "\n",
        "  input_y = Input(shape=(MAXLEN,))\n",
        "  y = Dense(second_output_size, activation=\"relu\")(input_y)\n",
        "  y = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "  combined = tf.keras.layers.concatenate([x.output, y.output])\n",
        "\n",
        "  z = Dense(final_hidden_size, activation=\"relu\")(combined)\n",
        "  z = Dense(address_predict_size, activation=\"sigmoid\")(z)\n",
        "\n",
        "  model = Model(inputs=[x.input, y.input], outputs=z)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMEj0XnvPsV2"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z59mtFbmPtZW"
      },
      "source": [
        "def generate_address(model, start_address):\n",
        "  # Evaluation step (generating address using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 2\n",
        "\n",
        "  input_eval = [tf.expand_dims(start_address[0], 0), tf.expand_dims(start_address[1], 0)]\n",
        "\n",
        "  # Empty string to store our results\n",
        "  generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  \n",
        "  predictions = model(input_eval)\n",
        "\n",
        "  predictions = predictions / temperature\n",
        "\n",
        "  # using probability\n",
        "  '''\n",
        "  generated = tf.random.categorical(predictions_np, num_samples=num_generate)[-1,0].numpy()  \n",
        "  '''\n",
        "\n",
        "  # using argmax\n",
        "  predictions_np = predictions.numpy()\n",
        "  predictions_np = np.squeeze(predictions_np,axis=0)\n",
        "  predictions_np = np.argsort(predictions_np)\n",
        "  generated = predictions_np [-num_generate:]\n",
        "\n",
        "  return generated"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "qZikMKo7Pw-G",
        "outputId": "e73c55d7-0530-4144-bed4-ebea3be06536"
      },
      "source": [
        "FIRST_OUTPUT_SIZE_array = [64, 128, 256, 512]\n",
        "SECOND_OUTPUT_SIZE_array = [8, 16, 32]\n",
        "FINAL_HIDDEN_SIZE_array = [128, 256, 512]\n",
        "BATCH_SIZE_array = [32, 64, 128]\n",
        "\n",
        "data = dict()\n",
        "continue_check = 0\n",
        "\n",
        "if os.path.isfile(f'/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv') == True:\n",
        "  continue_check = 1\n",
        "  before_data = pd.read_csv(f\"/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv\", names=[\"first_output_size\", \"second_output_size\", \"final_hidden_size\", \"batch_size\", \"epoch_num\", \"train_accuracy\", \"accuracy_except_0_and_1000\", \"first_number_accuracy\", \"second_number_accuracy\"])\n",
        "\n",
        "for FIRST_OUTPUT_SIZE in FIRST_OUTPUT_SIZE_array:\n",
        "  for SECOND_OUTPUT_SIZE in SECOND_OUTPUT_SIZE_array:\n",
        "    for FINAL_HIDDEN_SIZE in FINAL_HIDDEN_SIZE_array:\n",
        "      for BATCH_SIZE in BATCH_SIZE_array:\n",
        "        \n",
        "        if os.path.isdir(\"./training_checkpoints\") == True:\n",
        "          shutil.rmtree(\"./training_checkpoints\")\n",
        "\n",
        "        print(\"\\n\\nnew model start!!\")\n",
        "        print(f\"{FIRST_OUTPUT_SIZE}, {SECOND_OUTPUT_SIZE}, {FINAL_HIDDEN_SIZE}, {BATCH_SIZE}\\n\")\n",
        "\n",
        "        epoch_num_array = [10, 15, 20, 25, 30]\n",
        "\n",
        "        if continue_check == 1:\n",
        "          tmp = before_data.loc[before_data[\"first_output_size\"] == FIRST_OUTPUT_SIZE]\n",
        "          tmp = tmp[tmp[\"second_output_size\"] == SECOND_OUTPUT_SIZE]\n",
        "          tmp = tmp[tmp[\"final_hidden_size\"] == FINAL_HIDDEN_SIZE]\n",
        "          tmp = tmp[tmp[\"batch_size\"] == BATCH_SIZE]\n",
        "          if tmp.shape[0] == len(epoch_num_array):\n",
        "            continue\n",
        "          else:\n",
        "            continue_check = 0\n",
        "            epoch_num_array = epoch_num_array[tmp.shape[0]:]\n",
        "\n",
        "        model = build_model(ADDRESS_PREDICT_SIZE, FIRST_OUTPUT_SIZE, SECOND_OUTPUT_SIZE, FINAL_HIDDEN_SIZE, EMBEDDING_DIM, RNN_UNITS)\n",
        "        \n",
        "        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "        \n",
        "        checkpoint_dir = './training_checkpoints'\n",
        "        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "        checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "              filepath=checkpoint_prefix,\n",
        "              save_weights_only=True)\n",
        "        \n",
        "        history = model.fit([train_rnn_data, train_address_binary_input], train_delta_output, batch_size=BATCH_SIZE, epochs=epoch, callbacks=[checkpoint_callback])\n",
        "\n",
        "        model = build_model(ADDRESS_PREDICT_SIZE, FIRST_OUTPUT_SIZE, SECOND_OUTPUT_SIZE, FINAL_HIDDEN_SIZE, EMBEDDING_DIM, RNN_UNITS)\n",
        "        \n",
        "        for epoch_num in epoch_num_array:\n",
        "          model.load_weights(f'./training_checkpoints/ckpt_{epoch_num}')\n",
        "          model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "          total_num_except_0_1000 = len(test_rnn_data)\n",
        "          correct = 0\n",
        "          first_correct = 0\n",
        "          second_correct = 0\n",
        "\n",
        "          for i in tqdm(range(len(test_delta_output)), desc='check accuracy..'):\n",
        "            inp = [test_rnn_data[i].tolist(), test_address_binary_input[i].tolist()]\n",
        "            lstm_ans = generate_address(model, inp)\n",
        "            if test_delta_output[i] in lstm_ans:\n",
        "              correct += 1\n",
        "              if test_delta_output[i] == lstm_ans[0]:\n",
        "                first_correct += 1\n",
        "              if test_delta_output[i] == lstm_ans[1]:\n",
        "                second_correct += 1\n",
        "\n",
        "          data['first_output_size'] = [FIRST_OUTPUT_SIZE]\n",
        "          data['second_output_size'] = [SECOND_OUTPUT_SIZE]\n",
        "          data['final_hidden_size'] = [FINAL_HIDDEN_SIZE]\n",
        "          data['batch_size'] = [BATCH_SIZE]\n",
        "          data['epoch_num'] = [epoch_num]\n",
        "          data['train_accuracy'] = [round(history.history['accuracy'][epoch_num-1]*100,2)]\n",
        "          data['accuracy_except_0_and_1000'] = [round(correct/total_num_except_0_1000*100,2)]\n",
        "          data['first_number_accuracy'] = [round(first_correct/total_num_except_0_1000*100,2)]\n",
        "          data['second_number_accuracy'] = [round(second_correct/total_num_except_0_1000*100,2)]\n",
        "          \n",
        "          data_frame = pd.DataFrame(data)\n",
        "\n",
        "          data_frame.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv\", mode='a', header=False)\n",
        "\n",
        "          print(\"\\naccuracy except 0 and 1000\")\n",
        "          print(round(correct/total_num_except_0_1000*100,2))\n",
        "          print(\"first number accuracy\")\n",
        "          print(round(first_correct/total_num_except_0_1000*100,2))\n",
        "          print(\"second number accuracy\")\n",
        "          print(round(second_correct/total_num_except_0_1000*100,2))\n",
        "\n",
        "Cov = pd.read_csv(f\"/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv\", name[\"first_output_size\", \"second_output_size\", \"final_hidden_size\", \"batch_size\", \"epoch_num\", \"train_accuracy\", \"accuracy_except_0_and_1000\", \"first_number_accuracy\", \"second_number_accuracy\"])\n",
        "Cov.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-137f884b8c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/Colab Notebooks/seq_length_{seq_length}.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mcontinue_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mbefore_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"seq_length_{seq_length}.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"first_output_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"second_output_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"final_hidden_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch_num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy_except_0_and_1000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"first_number_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"second_number_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mFIRST_OUTPUT_SIZE\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFIRST_OUTPUT_SIZE_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seq_length_5.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep0vTkUAeR2U"
      },
      "source": [
        "##test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbW_Jqn-XLsO"
      },
      "source": [
        "a1 = [1,2,3]\n",
        "a2 = [4,5,6]\n",
        "a3 = [7,8,9]\n",
        "\n",
        "c = dict()\n",
        "\n",
        "for b1 in a1:\n",
        "  for b2 in a2:\n",
        "    for b3 in a3:\n",
        "      c['b1'] = [b1]\n",
        "      c['b2'] = [b2]\n",
        "      c['b3'] = [b3]\n",
        "      cpandas = pd.DataFrame(c)\n",
        "      cpandas.to_csv(\"test.csv\", mode='a', header=False)\n",
        "\n",
        "tmp = pd.DataFrame(pd.read_csv(\"test.csv\", names=[\"a1\", \"a2\", \"a3\"]))\n",
        "print(tmp)\n",
        "print(tmp.shape[0])\n",
        "tmp2 = tmp[tmp[\"a1\"] == 1]\n",
        "tmp2 = tmp2[tmp2[\"a2\"] == 5]\n",
        "print(tmp2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ0O1IpqYxws"
      },
      "source": [
        "os.path.isfile(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHJ_m6zpv460"
      },
      "source": [
        "if os.path.isdir(\"Untitled Folder\") == True:\n",
        "  os.rmdir(\"Untitled Folder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK0kfRg5Y0qK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}